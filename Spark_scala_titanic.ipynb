{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1:\n",
    "Did age have any affect on the survival of the passengers? Divide the passengers into age groups spanning 5 years each - [0, 5), [5, 10), [10, 15), â€¦ . For each group compute the number of passengers in each group. Then compute the percent of survivors in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+------+\n",
      "|survived| age|bucket|\n",
      "+--------+----+------+\n",
      "|       y|29.0|   5.0|\n",
      "|       y|null|  null|\n",
      "|       n| 2.0|   0.0|\n",
      "|       n|30.0|   6.0|\n",
      "|       n|25.0|   5.0|\n",
      "|       y|48.0|   9.0|\n",
      "|       y|63.0|  12.0|\n",
      "|       n|39.0|   7.0|\n",
      "|       y|53.0|  10.0|\n",
      "|       n|71.0|  14.0|\n",
      "|       n|47.0|   9.0|\n",
      "|       y|18.0|   3.0|\n",
      "|       y|24.0|   4.0|\n",
      "|       y|26.0|   5.0|\n",
      "|       y|80.0|  16.0|\n",
      "+--------+----+------+\n",
      "only showing top 15 rows\n",
      "\n",
      "+------+-------------------+----------------+------------------+                \n",
      "|bucket|survived_passengers|total_passengers|        percentage|\n",
      "+------+-------------------+----------------+------------------+\n",
      "|   8.0|                 20|              69|28.985507246376812|\n",
      "|   5.0|                 56|             160|              35.0|\n",
      "|  12.0|                 10|              27| 37.03703703703704|\n",
      "|   4.0|                 71|             184| 38.58695652173913|\n",
      "|   3.0|                 45|             116|38.793103448275865|\n",
      "|   2.0|                 11|              27| 40.74074074074074|\n",
      "|  11.0|                 11|              27| 40.74074074074074|\n",
      "|   6.0|                 54|             132|40.909090909090914|\n",
      "|   7.0|                 44|             100|              44.0|\n",
      "|   9.0|                 32|              66|48.484848484848484|\n",
      "|  10.0|                 21|              43|48.837209302325576|\n",
      "|   1.0|                 17|              31| 54.83870967741935|\n",
      "|   0.0|                 32|              50|              64.0|\n",
      "|  15.0|                  1|               1|             100.0|\n",
      "|  16.0|                  1|               1|             100.0|\n",
      "+------+-------------------+----------------+------------------+\n",
      "\n",
      "\n",
      "Yes! Age has affect on the survival of the passenger. As shown in the above table:\n",
      "1) The highest percentage ~64% of survivers belongs to 0 bucket which is age ranging between [0,5) years. \n",
      "2) The second highest percentage ~54.8% of survivers belongs to bucket 1 which has age ranging between [5,10) years.\n",
      "This clearly shows that children below age 10 were given priority over other passengers. \n",
      "Further, if we check more about the percentage of survived passengers in other buckets then we will realize\n",
      "that there were factors also in addition to age which played a role in it. \n",
      "However, the role of age cannot be undermined.\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.sql.functions._ \n",
    "\n",
    "//reading data from .tsv file\n",
    "val reader = spark.read\n",
    "reader.option(\"header\",true).option(\"inferSchema\",true).option(\"delimiter\",\"\\t\")\n",
    "val fileData = reader.csv(\"/Users/raghavnyati/Desktop/titanic.tsv\")\n",
    "\n",
    "//creating different buckets for age groups spanning 5 years\n",
    "import org.apache.spark.ml.feature.Bucketizer\n",
    "val splits = (0 to 20).map(_ * 5.0).toArray\n",
    "val bucketizer = new Bucketizer()\n",
    "bucketizer.setInputCol(\"age\").setOutputCol(\"bucket\").setSplits(splits)\n",
    "\n",
    "//assigning each row to respective bucket\n",
    "val bucketed = bucketizer.transform(fileData)\n",
    "bucketed.select(\"survived\", \"age\", \"bucket\").show(15)\n",
    "\n",
    "val df1 = bucketed.filter(col(\"survived\") === \"y\").groupBy(\"bucket\").agg(count(\"survived\").as(\"survived_passengers\"))\n",
    "\n",
    "val df2 = bucketed.groupBy(\"bucket\").agg(count(\"survived\").as(\"total_passengers\"))\n",
    "\n",
    "val joinedDF = df1.as('a).join(df2.as('b), col(\"a.bucket\") === col(\"b.bucket\")).select(col(\"a.bucket\"),col(\"a.survived_passengers\"),col(\"b.total_passengers\")).withColumn(\"percentage\", (col(\"a.survived_passengers\")/col(\"b.total_passengers\"))*100).sort(col(\"a.bucket\"))\n",
    "joinedDF.sort(\"percentage\").show\n",
    "\n",
    "val explanation: String =\n",
    "    \"\"\"\n",
    "      |Yes! Age has affect on the survival of the passenger. As shown in the above table:\n",
    "      |1) The highest percentage ~64% of survivers belongs to 0 bucket which is age ranging between [0,5) years. \n",
    "      |2) The second highest percentage ~54.8% of survivers belongs to bucket 1 which has age ranging between [5,10) years.\n",
    "      |This clearly shows that children below age 10 were given priority over other passengers. \n",
    "      |Further, if we check more about the percentage of survived passengers in other buckets then we will realize\n",
    "      |that there were factors also in addition to age which played a role in it. \n",
    "      |However, the role of age cannot be undermined.\n",
    "      \"\"\".stripMargin\n",
    "\n",
    "println(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2:\n",
    "For the following problems divide the data into a training set and a test set. After you have created your models in problems 2-4 compute the percent false positives and false negatives you get from your model on the test set.\n",
    "\n",
    "Logistic on age. Using logistic regression with independent variable age and dependent variable survived create a model to classify passengers as survivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [-0.0026351308410778903] Intercept: -0.32515461615182006\n",
      "\n",
      "Showing top 5 rows from wrong predictions: \n",
      "+--------+------+------+--------+-----+--------------------+--------------------+----------+\n",
      "|survived|   sex|   age|features|label|       rawPrediction|         probability|prediction|\n",
      "+--------+------+------+--------+-----+--------------------+--------------------+----------+\n",
      "|       y|female|0.1667|[0.1667]|  1.0|[0.32559389246302...|[0.58068691839705...|       0.0|\n",
      "|       y|female|   1.0|   [1.0]|  1.0|[0.32778974699289...|[0.58122149125606...|       0.0|\n",
      "|       y|female|   1.0|   [1.0]|  1.0|[0.32778974699289...|[0.58122149125606...|       0.0|\n",
      "|       y|female|   2.0|   [2.0]|  1.0|[0.33042487783397...|[0.58186275257119...|       0.0|\n",
      "|       y|female|   5.0|   [5.0]|  1.0|[0.33833027035720...|[0.58378486871137...|       0.0|\n",
      "+--------+------+------+--------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+------+\n",
      "|label|Errors|\n",
      "+-----+------+\n",
      "|  1.0|   128|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-------+\n",
      "|label|Correct|\n",
      "+-----+-------+\n",
      "|  0.0|    173|\n",
      "+-----+-------+\n",
      "\n",
      "Accuracy: 0.5804506864161848\n",
      "Total count = 301\n",
      "Total Correct = 173\n",
      "Total Wrong = 128\n",
      "True Negative = 173.0\n",
      "True Positive = 0.0\n",
      "False Negative = 128.0\n",
      "False Positive = 0.0\n",
      "Ratio Wrong = 0.42524916943521596\n",
      "Ratio Correct = 0.574750830564784\n",
      "Area under the precision-recall curve: 0.5459343387934532\n",
      "Accuracy or area under ROC curve : 0.5804506864161848\n",
      "\n",
      "+----------------- Confusion matrix ----------------------+\n",
      "                | Actual = 0           |     Actual = 1                      \n",
      "+----------------+------------+---------------------------+\n",
      " Predicted = 0  | 173.000000           |     0.000000                       \n",
      " Predicted = 1  | 128.000000           |     0.000000                       \n",
      "+----------------+------------+---------------------------+\n",
      "         "
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructField, StructType, StringType, DoubleType, IntegerType}\n",
    "import scala.collection.mutable\n",
    "import org.apache.spark.ml.feature.RFormula\n",
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "import org.apache.spark.ml.classification.{LogisticRegression, LogisticRegressionModel}\n",
    "\n",
    "//creating custom schema for required data fields\n",
    "val schema = new StructType(Array(\n",
    "  new StructField(\"survived\", StringType, true),\n",
    "  new StructField(\"sex\", StringType, true),\n",
    "  new StructField(\"age\", DoubleType, true)))\n",
    "\n",
    "//reading from tsv file in custom schema \n",
    "val df = spark.read.format(\"csv\").\n",
    "                     schema(schema).\n",
    "                     option(\"header\",true).\n",
    "                     option(\"delimiter\",\"\\t\").\n",
    "                     load(\"/Users/raghavnyati/Desktop/titanic.tsv\")\n",
    "\n",
    "//filtering data for age!=null\n",
    "val data = df.filter(\"age is not null\")\n",
    "\n",
    "//splitting data into training (70%) and testing (30%) data\n",
    "val Array(train, test) = data.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "//creating logistic regression model\n",
    "val stages = new mutable.ArrayBuffer[PipelineStage]()\n",
    "stages += new RFormula().setFormula(\"survived ~ age\")\n",
    "stages += new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\")\n",
    "val pipeline = new Pipeline().setStages(stages.toArray)\n",
    "\n",
    "//training network\n",
    "val pipelineModel = pipeline.fit(train)\n",
    "val lorModel = pipelineModel.stages.last.asInstanceOf[LogisticRegressionModel]\n",
    "println(s\"Weights: ${lorModel.coefficients} Intercept: ${lorModel.intercept}\")\n",
    "\n",
    "// Preparing test data\n",
    "val titanicFormala = new RFormula().setFormula(\"survived ~ age\")\n",
    "val fittedRF = titanicFormala.fit(test)\n",
    "val preparedDF = fittedRF.transform(test) \n",
    "\n",
    "val predictions = lorModel.transform(preparedDF)\n",
    "\n",
    "//counting wrong predictions\n",
    "import org.apache.spark.sql.functions._\n",
    "val wrongPredictions = predictions.where(expr(\"label != prediction\"))\n",
    "println(\"\\nShowing top 5 rows from wrong predictions: \")\n",
    "wrongPredictions.show(5)\n",
    "\n",
    "val countErrors = wrongPredictions.groupBy(\"label\").agg(count(\"prediction\").alias(\"Errors\"))\n",
    "countErrors.show\n",
    "\n",
    "//counting correct predictions\n",
    "val correctPredictions = predictions.where(expr(\"label == prediction\"))\n",
    "val countCorrectPredictions = correctPredictions.groupBy(\"label\").agg(count(\"prediction\").alias(\"Correct\"))\n",
    "countCorrectPredictions.show\n",
    "\n",
    "//*********************************** Evaluating our model ********************************\n",
    "\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.ml.linalg.DenseVector\n",
    "\n",
    "val evaluator = new BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"rawPrediction\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "val lp = predictions.select( \"label\", \"prediction\")\n",
    "val totalCount = predictions.count()\n",
    "val totalCorrect = lp.filter(col(\"label\") === col(\"prediction\")).count()\n",
    "val totalWrong = lp.filter(not(col(\"label\") === col(\"prediction\"))).count()\n",
    "val trueNegative = lp.filter(col(\"prediction\") === 0.0).filter(col(\"label\") === col(\"prediction\")).count().toFloat\n",
    "val truePositive = lp.filter(col(\"prediction\") === 1.0).filter(col(\"label\") === col(\"prediction\")).count().toFloat\n",
    "val falseNegative = lp.filter(col(\"prediction\") === 0.0).filter(not(col(\"label\") === col(\"prediction\"))).count().toFloat\n",
    "val falsePositive = lp.filter(col(\"prediction\") === 1.0).filter(not(col(\"label\") === col(\"prediction\"))).count().toFloat\n",
    "val ratioWrong = totalWrong.toDouble/totalCount.toDouble\n",
    "val ratioCorrect = totalCorrect.toDouble/totalCount.toDouble\n",
    "\n",
    "println(\"Accuracy: \" + accuracy)\n",
    "println(\"Total count = \" + totalCount)\n",
    "println(\"Total Correct = \" + totalCorrect)\n",
    "println(\"Total Wrong = \" + totalWrong)\n",
    "println(\"True Negative = \" + trueNegative)\n",
    "println(\"True Positive = \" + truePositive)\n",
    "println(\"False Negative = \" + falseNegative)\n",
    "println(\"False Positive = \" + falsePositive)\n",
    "println(\"Ratio Wrong = \" + ratioWrong)\n",
    "println(\"Ratio Correct = \" + ratioCorrect)\n",
    "\n",
    "val  predictionAndLabels =predictions.select(\"rawPrediction\", \"label\").rdd.map(x => (x(0).asInstanceOf[DenseVector](1), x(1).asInstanceOf[Double]))\n",
    "val metrics = new BinaryClassificationMetrics(predictionAndLabels)\n",
    "println(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\n",
    "println(\"Accuracy or area under ROC curve : \" + metrics.areaUnderROC)\n",
    "\n",
    "println(\"\")\n",
    "printf(s\"\"\"\n",
    "          |+----------------- Confusion matrix ----------------------+\n",
    "          ||                | %-15s      |     %-15s                 \n",
    "          |+----------------+------------+---------------------------+\n",
    "          || Predicted = 0  | %-15f      |     %-15f                \n",
    "          || Predicted = 1  | %-15f      |     %-15f                \n",
    "          |+----------------+------------+---------------------------+\n",
    "         \"\"\".stripMargin, \"Actual = 0\", \"Actual = 1\", trueNegative, falsePositive, falseNegative, truePositive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: \n",
    "Logistic on age, sex and pclass. Same as problem two but use independent variables sex, age, and pclass. Since sex and pclass are categorical they need special treatment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+------+-----------+\n",
      "|survived|   sex| age|pclass|indexed_sex|\n",
      "+--------+------+----+------+-----------+\n",
      "|       y|female|29.0| first|        1.0|\n",
      "|       n|female| 2.0| first|        1.0|\n",
      "|       n|  male|30.0| first|        0.0|\n",
      "|       n|female|25.0| first|        1.0|\n",
      "|       y|  male|48.0| first|        0.0|\n",
      "|       y|female|63.0| first|        1.0|\n",
      "|       n|  male|39.0| first|        0.0|\n",
      "|       y|female|53.0| first|        1.0|\n",
      "|       n|  male|71.0| first|        0.0|\n",
      "|       n|  male|47.0| first|        0.0|\n",
      "+--------+------+----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Weights: [-0.011606839911331652,2.4536931565469082,0.5947070768342849] Intercept: -1.5026982336399672\n",
      "\n",
      "Showing top 5 rows from wrong predictions: \n",
      "+--------+------+---+------+-----------+--------------+-------------+-----+--------------------+--------------------+----------+\n",
      "|survived|   sex|age|pclass|indexed_sex|indexed_pclass|     features|label|       rawPrediction|         probability|prediction|\n",
      "+--------+------+---+------+-----------+--------------+-------------+-----+--------------------+--------------------+----------+\n",
      "|       n|female|1.0| third|        1.0|           0.0|[1.0,1.0,0.0]|  0.0|[-0.9393880829956...|[0.28102396353714...|       1.0|\n",
      "|       n|female|2.0| third|        1.0|           0.0|[2.0,1.0,0.0]|  0.0|[-0.9277812430842...|[0.28337506890624...|       1.0|\n",
      "|       n|female|8.0| third|        1.0|           0.0|[8.0,1.0,0.0]|  0.0|[-0.8581402036162...|[0.29772805681619...|       1.0|\n",
      "|       n|female|9.0| third|        1.0|           0.0|[9.0,1.0,0.0]|  0.0|[-0.8465333637049...|[0.30016056884632...|       1.0|\n",
      "|       n|female|9.0| third|        1.0|           0.0|[9.0,1.0,0.0]|  0.0|[-0.8465333637049...|[0.30016056884632...|       1.0|\n",
      "+--------+------+---+------+-----------+--------------+-------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----+------+\n",
      "|label|Errors|\n",
      "+-----+------+\n",
      "|  0.0|    28|\n",
      "|  1.0|    42|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-------+\n",
      "|label|Correct|\n",
      "+-----+-------+\n",
      "|  0.0|    164|\n",
      "|  1.0|     90|\n",
      "+-----+-------+\n",
      "\n",
      "Accuracy: 0.8045494002525252\n",
      "Total count = 324\n",
      "Total Correct = 254\n",
      "Total Wrong = 70\n",
      "True Negative = 164.0\n",
      "True Positive = 90.0\n",
      "False Negative = 42.0\n",
      "False Positive = 28.0\n",
      "Ratio Wrong = 0.21604938271604937\n",
      "Ratio Correct = 0.7839506172839507\n",
      "Area under the precision-recall curve: 0.8001711080443081\n",
      "Accuracy or area under ROC curve : 0.8045494002525252\n",
      "\n",
      "+----------------- Confusion matrix ----------------------+\n",
      "                | Actual = 0           |     Actual = 1                      \n",
      "+----------------+------------+---------------------------+\n",
      " Predicted = 0  | 164.000000           |     28.000000                      \n",
      " Predicted = 1  | 42.000000            |     90.000000                      \n",
      "+----------------+------------+---------------------------+\n",
      "         "
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructField, StructType, StringType, DoubleType, IntegerType}\n",
    "import scala.collection.mutable\n",
    "import org.apache.spark.ml.feature.RFormula\n",
    "import org.apache.spark.ml.{Pipeline, PipelineStage}\n",
    "import org.apache.spark.ml.classification.{LogisticRegression, LogisticRegressionModel}\n",
    "\n",
    "//creating custom schema for required data fields\n",
    "val schema = new StructType(Array(\n",
    "  new StructField(\"survived\", StringType, true),\n",
    "  new StructField(\"sex\", StringType, true),\n",
    "  new StructField(\"age\", DoubleType, true),\n",
    "  new StructField(\"pclass\", StringType, true)))\n",
    "\n",
    "//reading from tsv file in custom schema \n",
    "val df = spark.read.format(\"csv\").\n",
    "                     schema(schema).\n",
    "                     option(\"header\",true).\n",
    "                     option(\"delimiter\",\"\\t\").\n",
    "                     load(\"/Users/raghavnyati/Desktop/titanic.tsv\")\n",
    "\n",
    "//filtering data for age!=null\n",
    "val data = df.filter(\"age is not null\")\n",
    "\n",
    "//scaling categorical variables - sex and pclass\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "\n",
    "val sex_indexer: StringIndexer = new StringIndexer().\n",
    "  setInputCol(\"sex\").\n",
    "  setOutputCol(\"indexed_sex\")\n",
    "\n",
    "val pclass_indexer = new StringIndexer().\n",
    "    setInputCol(\"pclass\").\n",
    "    setOutputCol(\"indexed_pclass\")\n",
    "\n",
    "val nDataFrame = sex_indexer.fit(data).transform(data)\n",
    "nDataFrame.show(10)\n",
    "\n",
    "val newDf = pclass_indexer.fit(nDataFrame).transform(nDataFrame) \n",
    "\n",
    "//splitting data into training (70%) and testing (30%) data\n",
    "val Array(train, test) = newDf.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "//creating logistic regression model\n",
    "val stages = new mutable.ArrayBuffer[PipelineStage]()\n",
    "stages += new RFormula().setFormula(\"survived ~ age + indexed_sex + indexed_pclass\")\n",
    "stages += new LogisticRegression().setLabelCol(\"label\").setFeaturesCol(\"features\")\n",
    "val pipeline = new Pipeline().setStages(stages.toArray)\n",
    "\n",
    "//training data\n",
    "val pipelineModel = pipeline.fit(train)\n",
    "val lorModel = pipelineModel.stages.last.asInstanceOf[LogisticRegressionModel]\n",
    "println(s\"Weights: ${lorModel.coefficients} Intercept: ${lorModel.intercept}\")\n",
    "\n",
    "// Preparing test data\n",
    "val titanicFormala = new RFormula().setFormula(\"survived ~ age + indexed_sex + indexed_pclass\")\n",
    "val fittedRF = titanicFormala.fit(test)\n",
    "val preparedDF = fittedRF.transform(test) \n",
    "\n",
    "val predictions = lorModel.transform(preparedDF)\n",
    "\n",
    "//counting wrong predictions\n",
    "import org.apache.spark.sql.functions._\n",
    "val wrongPredictions = predictions.where(expr(\"label != prediction\"))\n",
    "println(\"\\nShowing top 5 rows from wrong predictions: \")\n",
    "wrongPredictions.show(5)\n",
    "\n",
    "val countErrors = wrongPredictions.groupBy(\"label\").agg(count(\"prediction\").alias(\"Errors\"))\n",
    "countErrors.show\n",
    "\n",
    "//counting correct predictions\n",
    "val correctPredictions = predictions.where(expr(\"label == prediction\"))\n",
    "val countCorrectPredictions = correctPredictions.groupBy(\"label\").agg(count(\"prediction\").alias(\"Correct\"))\n",
    "countCorrectPredictions.show\n",
    "\n",
    "//****************************Evaluating our model********************************\n",
    "\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.ml.linalg.DenseVector\n",
    "\n",
    "val evaluator = new BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"rawPrediction\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "val lp = predictions.select( \"label\", \"prediction\")\n",
    "val totalCount = predictions.count()\n",
    "val totalCorrect = lp.filter(col(\"label\") === col(\"prediction\")).count()\n",
    "val totalWrong = lp.filter(not(col(\"label\") === col(\"prediction\"))).count()\n",
    "val trueNegative = lp.filter(col(\"prediction\") === 0.0).filter(col(\"label\") === col(\"prediction\")).count().toFloat\n",
    "val truePositive = lp.filter(col(\"prediction\") === 1.0).filter(col(\"label\") === col(\"prediction\")).count().toFloat\n",
    "val falseNegative = lp.filter(col(\"prediction\") === 0.0).filter(not(col(\"label\") === col(\"prediction\"))).count().toFloat\n",
    "val falsePositive = lp.filter(col(\"prediction\") === 1.0).filter(not(col(\"label\") === col(\"prediction\"))).count().toFloat\n",
    "val ratioWrong = totalWrong.toDouble/totalCount.toDouble\n",
    "val ratioCorrect = totalCorrect.toDouble/totalCount.toDouble\n",
    "\n",
    "println(\"Accuracy: \" + accuracy)\n",
    "println(\"Total count = \" + totalCount)\n",
    "println(\"Total Correct = \" + totalCorrect)\n",
    "println(\"Total Wrong = \" + totalWrong)\n",
    "println(\"True Negative = \" + trueNegative)\n",
    "println(\"True Positive = \" + truePositive)\n",
    "println(\"False Negative = \" + falseNegative)\n",
    "println(\"False Positive = \" + falsePositive)\n",
    "println(\"Ratio Wrong = \" + ratioWrong)\n",
    "println(\"Ratio Correct = \" + ratioCorrect)\n",
    "\n",
    "val  predictionAndLabels =predictions.select(\"rawPrediction\", \"label\").rdd.map(x => (x(0).asInstanceOf[DenseVector](1), x(1).asInstanceOf[Double]))\n",
    "val metrics = new BinaryClassificationMetrics(predictionAndLabels)\n",
    "println(\"Area under the precision-recall curve: \" + metrics.areaUnderPR)\n",
    "println(\"Accuracy or area under ROC curve : \" + metrics.areaUnderROC)\n",
    "\n",
    "println(\"\")\n",
    "printf(s\"\"\"\n",
    "          |+----------------- Confusion matrix ----------------------+\n",
    "          ||                | %-15s      |     %-15s                 \n",
    "          |+----------------+------------+---------------------------+\n",
    "          || Predicted = 0  | %-15f      |     %-15f                \n",
    "          || Predicted = 1  | %-15f      |     %-15f                \n",
    "          |+----------------+------------+---------------------------+\n",
    "         \"\"\".stripMargin, \"Actual = 0\", \"Actual = 1\", trueNegative, falsePositive, falseNegative, truePositive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: \n",
    "Decision tree. Instead of using logistic regression use Decision tree with the independent variables sex, age, and pclass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+------+-----------+--------------+\n",
      "|survived|   sex| age|pclass|indexed_sex|indexed_pclass|\n",
      "+--------+------+----+------+-----------+--------------+\n",
      "|       y|female|29.0| first|        1.0|           1.0|\n",
      "|       n|female| 2.0| first|        1.0|           1.0|\n",
      "|       n|  male|30.0| first|        0.0|           1.0|\n",
      "|       n|female|25.0| first|        1.0|           1.0|\n",
      "|       y|  male|48.0| first|        0.0|           1.0|\n",
      "+--------+------+----+------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+----------+\n",
      "|survived|   sex| age|pclass|indexed_sex|indexed_pclass|      features|label|prediction|\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+----------+\n",
      "|       n|female| 9.0| third|        1.0|           0.0| [9.0,1.0,0.0]|  0.0|       0.0|\n",
      "|       n|female| 9.0| third|        1.0|           0.0| [9.0,1.0,0.0]|  0.0|       0.0|\n",
      "|       n|female|17.0| third|        1.0|           0.0|[17.0,1.0,0.0]|  0.0|       0.5|\n",
      "|       n|female|18.0| third|        1.0|           0.0|[18.0,1.0,0.0]|  0.0|       0.5|\n",
      "|       n|female|18.0| third|        1.0|           0.0|[18.0,1.0,0.0]|  0.0|       0.5|\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+----------+--------------------+\n",
      "|survived|   sex| age|pclass|indexed_sex|indexed_pclass|      features|label|prediction|binarized_prediction|\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+----------+--------------------+\n",
      "|       n|female| 9.0| third|        1.0|           0.0| [9.0,1.0,0.0]|  0.0|       0.0|                 0.0|\n",
      "|       n|female| 9.0| third|        1.0|           0.0| [9.0,1.0,0.0]|  0.0|       0.0|                 0.0|\n",
      "|       n|female|17.0| third|        1.0|           0.0|[17.0,1.0,0.0]|  0.0|       0.5|                 0.0|\n",
      "|       n|female|18.0| third|        1.0|           0.0|[18.0,1.0,0.0]|  0.0|       0.5|                 0.0|\n",
      "|       n|female|18.0| third|        1.0|           0.0|[18.0,1.0,0.0]|  0.0|       0.5|                 0.0|\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+------------------+--------------------+\n",
      "|survived|   sex| age|pclass|indexed_sex|indexed_pclass|      features|label|        prediction|binarized_prediction|\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+------------------+--------------------+\n",
      "|       n|female|25.0| first|        1.0|           1.0|[25.0,1.0,1.0]|  0.0|               1.0|                 1.0|\n",
      "|       n|female|30.0|second|        1.0|           2.0|[30.0,1.0,2.0]|  0.0|0.8545454545454545|                 1.0|\n",
      "|       n|female|63.0| first|        1.0|           1.0|[63.0,1.0,1.0]|  0.0|0.9555555555555556|                 1.0|\n",
      "|       n|  male|50.0| first|        0.0|           1.0|[50.0,0.0,1.0]|  0.0|0.5714285714285714|                 1.0|\n",
      "|       n|  male|50.0| first|        0.0|           1.0|[50.0,0.0,1.0]|  0.0|0.5714285714285714|                 1.0|\n",
      "|       n|  male|51.0| first|        0.0|           1.0|[51.0,0.0,1.0]|  0.0|0.5714285714285714|                 1.0|\n",
      "|       n|  male|52.0| first|        0.0|           1.0|[52.0,0.0,1.0]|  0.0|0.5714285714285714|                 1.0|\n",
      "|       n|  male|54.0| first|        0.0|           1.0|[54.0,0.0,1.0]|  0.0|0.5714285714285714|                 1.0|\n",
      "|       y|female| 2.0| third|        1.0|           0.0| [2.0,1.0,0.0]|  1.0|               0.4|                 0.0|\n",
      "|       y|female| 5.0| third|        1.0|           0.0| [5.0,1.0,0.0]|  1.0|               0.4|                 0.0|\n",
      "|       y|female| 5.0| third|        1.0|           0.0| [5.0,1.0,0.0]|  1.0|               0.4|                 0.0|\n",
      "|       y|female| 9.0| third|        1.0|           0.0| [9.0,1.0,0.0]|  1.0|               0.0|                 0.0|\n",
      "|       y|female|13.0| third|        1.0|           0.0|[13.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "|       y|female|16.0| third|        1.0|           0.0|[16.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "|       y|female|16.0| third|        1.0|           0.0|[16.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "|       y|female|17.0| third|        1.0|           0.0|[17.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "|       y|female|18.0| third|        1.0|           0.0|[18.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "|       y|female|18.0| third|        1.0|           0.0|[18.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "|       y|female|18.0| third|        1.0|           0.0|[18.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "|       y|female|19.0| third|        1.0|           0.0|[19.0,1.0,0.0]|  1.0|               0.5|                 0.0|\n",
      "+--------+------+----+------+-----------+--------------+--------------+-----+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+------+\n",
      "|label|Errors|\n",
      "+-----+------+\n",
      "|  0.0|     8|\n",
      "|  1.0|    60|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-------+\n",
      "|label|Correct|\n",
      "+-----+-------+\n",
      "|  0.0|    180|\n",
      "|  1.0|     79|\n",
      "+-----+-------+\n",
      "\n",
      "Accuracy: 0.8658923924690035\n",
      "Total count = 327\n",
      "Total Correct = 49\n",
      "Total Wrong = 278\n",
      "True Negative = 21.0\n",
      "True Positive = 28.0\n",
      "False Negative = 4.0\n",
      "False Positive = 1.0\n",
      "Ratio Wrong = 0.8501529051987767\n",
      "Ratio Correct = 0.14984709480122324\n",
      "\n",
      "+----------------- Confusion matrix ----------------------+\n",
      "                | Actual = 0           |     Actual = 1                      \n",
      "+----------------+------------+---------------------------+\n",
      " Predicted = 0  | 21.000000            |     1.000000                       \n",
      " Predicted = 1  | 4.000000             |     28.000000                      \n",
      "+----------------+------------+---------------------------+\n",
      "         "
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.regression.DecisionTreeRegressionModel\n",
    "import org.apache.spark.ml.regression.DecisionTreeRegressor\n",
    "import org.apache.spark.sql.types.{StructField, StructType, StringType, DoubleType, IntegerType}\n",
    "import org.apache.spark.ml.feature.RFormula\n",
    "\n",
    "newDf.show(5)\n",
    "\n",
    "val supervised = new RFormula().setFormula(\"survived ~ age + indexed_sex + indexed_pclass\")\n",
    "\n",
    "val fittedRF = supervised.fit(newDf)\n",
    "val preparedDF = fittedRF.transform(newDf)\n",
    "val Array(train, test) = preparedDF.randomSplit(Array(0.7, 0.3))\n",
    "\n",
    "val dt = new DecisionTreeRegressor().setLabelCol(\"label\").setFeaturesCol(\"features\")\n",
    "\n",
    "val model = dt.fit(train)\n",
    "\n",
    "val predictions = model.transform(test)\n",
    "predictions.show(5)\n",
    "\n",
    "import org.apache.spark.ml.feature.Binarizer\n",
    "\n",
    "val binarizer: Binarizer = new Binarizer().\n",
    "  setInputCol(\"prediction\").\n",
    "  setOutputCol(\"binarized_prediction\").\n",
    "  setThreshold(0.5)\n",
    "\n",
    "val predictionBinary = binarizer.transform(predictions) \n",
    "predictionBinary.show(5)\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "val wrongPredictions = predictionBinary.where(expr(\"label != binarized_prediction\"))\n",
    "wrongPredictions.show\n",
    "\n",
    "val countErrors = wrongPredictions.groupBy(\"label\").agg(count(\"prediction\").alias(\"Errors\"))\n",
    "countErrors.show\n",
    "\n",
    "val correctPredictions = predictionBinary.where(expr(\"label == binarized_prediction\"))\n",
    "val countCorrectPredictions = correctPredictions.groupBy(\"label\").agg(count(\"prediction\").alias(\"Correct\"))\n",
    "countCorrectPredictions.show\n",
    "\n",
    "//***********************************************************************************\n",
    "\n",
    "\n",
    "import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n",
    "\n",
    "val evaluator = new BinaryClassificationEvaluator().setLabelCol(\"label\").setRawPredictionCol(\"prediction\").setMetricName(\"areaUnderROC\")\n",
    "val accuracy = evaluator.evaluate(predictions)\n",
    "val lp = predictions.select( \"label\", \"prediction\")\n",
    "val totalCount = predictions.count()\n",
    "val totalCorrect = lp.filter(col(\"label\") === col(\"prediction\")).count()\n",
    "val totalWrong = lp.filter(not(col(\"label\") === col(\"prediction\"))).count()\n",
    "val trueNegative = lp.filter(col(\"prediction\") === 0.0).filter(col(\"label\") === col(\"prediction\")).count().toFloat\n",
    "val truePositive = lp.filter(col(\"prediction\") === 1.0).filter(col(\"label\") === col(\"prediction\")).count().toFloat\n",
    "val falseNegative = lp.filter(col(\"prediction\") === 0.0).filter(not(col(\"label\") === col(\"prediction\"))).count().toFloat\n",
    "val falsePositive = lp.filter(col(\"prediction\") === 1.0).filter(not(col(\"label\") === col(\"prediction\"))).count().toFloat\n",
    "val ratioWrong = totalWrong.toDouble/totalCount.toDouble\n",
    "val ratioCorrect = totalCorrect.toDouble/totalCount.toDouble\n",
    "\n",
    "println(\"Accuracy: \" + accuracy)\n",
    "println(\"Total count = \" + totalCount)\n",
    "println(\"Total Correct = \" + totalCorrect)\n",
    "println(\"Total Wrong = \" + totalWrong)\n",
    "println(\"True Negative = \" + trueNegative)\n",
    "println(\"True Positive = \" + truePositive)\n",
    "println(\"False Negative = \" + falseNegative)\n",
    "println(\"False Positive = \" + falsePositive)\n",
    "println(\"Ratio Wrong = \" + ratioWrong)\n",
    "println(\"Ratio Correct = \" + ratioCorrect)\n",
    "\n",
    "println(\"\")\n",
    "printf(s\"\"\"\n",
    "          |+----------------- Confusion matrix ----------------------+\n",
    "          ||                | %-15s      |     %-15s                 \n",
    "          |+----------------+------------+---------------------------+\n",
    "          || Predicted = 0  | %-15f      |     %-15f                \n",
    "          || Predicted = 1  | %-15f      |     %-15f                \n",
    "          |+----------------+------------+---------------------------+\n",
    "         \"\"\".stripMargin, \"Actual = 0\", \"Actual = 1\", trueNegative, falsePositive, falseNegative, truePositive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5:\n",
    "How do the models created in problems 2-4 compare based on the false positives & false negatives the produce on your test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution:\n",
    "In question 2: \n",
    "We got the confusion matrix like this: \n",
    "\n",
    "+----------------- Confusion matrix ----------------------+                                                           \n",
    " ++++++++++++ | Actual = 0           |     Actual = 1                                                               \n",
    "+---------------+------------+---------------------------+                                                           \n",
    " Predicted = 0  | 173.000000           |     0.000000                       \n",
    " Predicted = 1  | 128.000000           |     0.000000                       \n",
    "+----------------+------------+---------------------------+\n",
    "\n",
    "In question 3, we got the confusion matrix as below: \n",
    "\n",
    "+----------------- Confusion matrix ----------------------+                                                           \n",
    "  ++++++++++++| Actual = 0           |     Actual = 1                                                               \n",
    "+----------------+------------+---------------------------+                                                           \n",
    " Predicted = 0  | 164.000000           |     28.000000                                                                 \n",
    " Predicted = 1  | 42.000000            |     90.000000                                                                 \n",
    "+----------------+------------+---------------------------+                                                           \n",
    "\n",
    "In question 4, we got the confusion matrix as below: \n",
    "\n",
    "+----------------- Confusion matrix ----------------------+                                                           \n",
    " ++++++++++++  | Actual = 0           |     Actual = 1                                                              \n",
    "+----------------+------------+---------------------------+                                                           \n",
    " Predicted = 0  | 21.000000            |     1.000000                                                                 \n",
    " Predicted = 1  | 4.000000             |     28.000000                                                                \n",
    "+----------------+------------+---------------------------+                                                           \n",
    "\n",
    "Now,on comparing the values for all three models, I found the follwoing: \n",
    "1) Got the highest accuracy in question 4 model using decision tree.\n",
    "2) The lowest false positive is in model for question 2 where we had one independent and one dependent variable.\n",
    "   Also, the value for false Positive for model with decision tree in question 4 is less than the the model in\n",
    "   question 3.\n",
    "3) The value for False Negative is lowest in the case of question 4 model with decision trees. If we talk about\n",
    "   False Negative values than Model4 is thes best followed by model 3 which is better than model 2.\n",
    "   \n",
    "   On comparing all three models in question 2-4, I found the model in question 4 is the best with highest accuracy of 86.58%. Model 3 is the second best here with accuracy of 80.45% and model 2 has accuracy of 58.04%. Therefore, it is apparent that number of independent variables play a vital role in training a network. As in question 2, we had age as only independent variable while in question 3 we had pclass and sex in addition to age as an independent variables. \n",
    "   \n",
    "   Note- Model 4is decision tree mdel trained in question 4. While model 2 referes to the Logistic Regression model trained in question 2 and model 3 refers to the Logistic Regression model trained in question 3. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
